{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmd8E3-szU35"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('spam.csv', encoding='latin1')"
      ],
      "metadata": {
        "id": "LUWebgQS0gp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(5)"
      ],
      "metadata": {
        "id": "dCX9LTd019F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "RP0CBKPE19Cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1 . Data Cleaning\n",
        "#2 . EDA\n",
        "#3 . Text Processing\n",
        "#4 . Model Building\n",
        "#5 . Evaluation\n",
        "#6 . Deploy"
      ],
      "metadata": {
        "id": "9HAzmnWl18_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "***1. DATA CLEANING***"
      ],
      "metadata": {
        "id": "CUGi20arpueh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "sSmidSlr188S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop last 3 cols\n",
        "df.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'],inplace=True)"
      ],
      "metadata": {
        "id": "ucNkMwVv185B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(5)"
      ],
      "metadata": {
        "id": "vOLztQpk181i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#renaming the cols\n",
        "df.rename(columns={'v1':'target','v2':'text'},inplace=True)\n",
        "df.sample(5)"
      ],
      "metadata": {
        "id": "zjqubp0Z18yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()"
      ],
      "metadata": {
        "id": "WmskjwJR18vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['target'] = encoder.fit_transform(df['target'])"
      ],
      "metadata": {
        "id": "h3TSNYqf18s3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "811fb0df"
      },
      "source": [
        "!pip install streamlit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0daa94e"
      },
      "source": [
        "import streamlit as st\n",
        "import pickle\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "ps = PorterStemmer()\n",
        "\n",
        "\n",
        "# LOWER CASE t\n",
        "def transform_text(text):\n",
        "    text = text.lower()\n",
        "    # Download punkt_tab if not already downloaded\n",
        "    try:\n",
        "        nltk.data.find('tokenizers/punkt_tab')\n",
        "    except LookupError:\n",
        "        nltk.download('punkt_tab')\n",
        "    text = nltk.word_tokenize(text)\n",
        "\n",
        "    y = []\n",
        "    for i in text:\n",
        "        if i.isalnum():\n",
        "            y.append(i)\n",
        "\n",
        "    text = y[:]\n",
        "    y.clear()\n",
        "\n",
        "    # Download stopwords if not already downloaded\n",
        "    try:\n",
        "        stopwords.words('english')\n",
        "    except LookupError:\n",
        "        nltk.download('stopwords')\n",
        "\n",
        "    for i in text:\n",
        "        if i not in stopwords.words('english') and i not in string.punctuation:\n",
        "            y.append(i)\n",
        "\n",
        "    text = y[:]\n",
        "    y.clear()\n",
        "\n",
        "    for i in text:\n",
        "        y.append(ps.stem(i))\n",
        "\n",
        "    return \" \".join(y)\n",
        "\n",
        "\n",
        "with open('vectorizer.pkl', 'rb') as f:\n",
        "    tfidf = pickle.load(f)\n",
        "\n",
        "with open('model.pkl', 'rb') as f:\n",
        "    model = pickle.load(f)\n",
        "\n",
        "st.title(\"Email/SMS Spam Classifyer\")\n",
        "\n",
        "input_sms = st.text_input(\"Enter the email message\")\n",
        "\n",
        "# Preprocess\n",
        "transform_sms = transform_text(input_sms)\n",
        "# Vectorize\n",
        "vector_input = tfidf.transform([transform_sms])# Predict\n",
        "result = model.predict(vector_input)\n",
        "# Display\n",
        "if result == 1:\n",
        "    st.header(\"Spam\")\n",
        "else:\n",
        "    st.header(\"Not Spam\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "8lyac4WhrYtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#finding missing values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "_qITpeLfrYqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#finding the duplicated values\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "c6GdAl0RrYnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing duplicates\n",
        "df = df.drop_duplicates(keep='first')"
      ],
      "metadata": {
        "id": "SS_fo6xNrYkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "LrIMU4O4sFb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "zvCipkD7rYhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***2. EDA(EXPLORATORY DATA ANALYSIS)***"
      ],
      "metadata": {
        "id": "DYbyo96dsP72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "UtClSuuZsW86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['target'].value_counts()"
      ],
      "metadata": {
        "id": "nWycekhGsW5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.pie(df['target'].value_counts(),labels=['ham','spam'],autopct=\"%0.2f\")\n",
        "plt.show"
      ],
      "metadata": {
        "id": "OMlBul97sW27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "here.... the data is imbalenced"
      ],
      "metadata": {
        "id": "3SLn-eXe59PQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "fjQrk2eGsWz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "LgqeYEHGsWws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['num_charachters'] = df['text'].apply(len)"
      ],
      "metadata": {
        "id": "sZTWTesCsWt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "-U7oE7O7sWrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "fetching the no. of  words\n"
      ],
      "metadata": {
        "id": "XNqpO2ln7EcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')\n",
        "df['num_words'] = df['text'].apply(lambda x:len(nltk.word_tokenize(x)))"
      ],
      "metadata": {
        "id": "Tgr1k3PosWoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "U3ad03dWsWlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['num_sentences'] = df['text'].apply(lambda x:len(nltk.sent_tokenize(x)))"
      ],
      "metadata": {
        "id": "zsn5cLPfsWit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "iqeank-asWf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['num_charachters','num_words','num_sentences']].describe()"
      ],
      "metadata": {
        "id": "FNnJCss0rYe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ham\n",
        "df[df['target'] == 0][['num_charachters','num_words','num_sentences']].describe()"
      ],
      "metadata": {
        "id": "Ra2qO6oa18p1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#spam\n",
        "df[df['target'] == 1][['num_charachters','num_words','num_sentences']].describe()"
      ],
      "metadata": {
        "id": "l4MxgnN218my"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "YotZ87Xx18jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=((15,5)))\n",
        "#ham\n",
        "sns.histplot(df[df['target'] == 0]['num_charachters'])\n",
        "#spam\n",
        "sns.histplot(df[df['target'] == 1]['num_charachters'],color = 'red')"
      ],
      "metadata": {
        "id": "MMGY95HkJaxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=((15,5)))\n",
        "#ham\n",
        "sns.histplot(df[df['target'] == 0]['num_words'])\n",
        "#spam\n",
        "sns.histplot(df[df['target'] == 1]['num_words'],color = 'red')"
      ],
      "metadata": {
        "id": "ntKYGU0sJatm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=((15,5)))\n",
        "#ham\n",
        "sns.histplot(df[df['target'] == 0]['num_sentences'])\n",
        "#spam\n",
        "sns.histplot(df[df['target'] == 1]['num_sentences'],color = 'red')"
      ],
      "metadata": {
        "id": "GZsgtU8IJaqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(df,hue='target')"
      ],
      "metadata": {
        "id": "uV_hDstpJamt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(df[['target','num_charachters','num_words','num_sentences']].corr(), annot=True)"
      ],
      "metadata": {
        "id": "ZWHCX2HjJakE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "DATA PREPROCESSING\n",
        ". LOWER CASE\n",
        ". TOKENIZATION\n",
        ". rEMOVING SPECIAL CHARACHTERS\n",
        ". REMOVING STOP WORDS AND PUNCTUATIONS\n",
        ". STEMMING\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "54kXJA92P8Ur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "ps = PorterStemmer()\n",
        "\n",
        "#LOWER CASE t\n",
        "def transform_text(text):\n",
        "  text = text.lower()\n",
        "  text = nltk.word_tokenize(text)\n",
        "\n",
        "  y =[]\n",
        "  for i in text:\n",
        "    if i.isalnum():\n",
        "      y.append(i)\n",
        "\n",
        "  text = y[:]\n",
        "  y.clear()\n",
        "\n",
        "  # Download stopwords if not already downloaded\n",
        "  try:\n",
        "      stopwords.words('english')\n",
        "  except LookupError:\n",
        "      nltk.download('stopwords')\n",
        "\n",
        "  for i in text:\n",
        "    if i not in stopwords.words('english') and i not in string.punctuation:\n",
        "      y.append(i)\n",
        "\n",
        "\n",
        "  text = y[:]\n",
        "  y.clear()\n",
        "\n",
        "  for i in text:\n",
        "    y.append(ps.stem(i))\n",
        "\n",
        "  return \" \".join(y)"
      ],
      "metadata": {
        "id": "PXKBbNENJag9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_text(\"Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\")"
      ],
      "metadata": {
        "id": "D0RJF_o7abnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'][0]"
      ],
      "metadata": {
        "id": "JaGX3WUNhi5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "ps.stem('loving')"
      ],
      "metadata": {
        "id": "MKV4xz08Jad1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['transformed_text'] = df['text'].apply(transform_text)"
      ],
      "metadata": {
        "id": "pKw5wDIcJaa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "NaV016L3JaX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "wc = WordCloud(width= 500,height=500,min_font_size= 10,background_color='white')"
      ],
      "metadata": {
        "id": "Th9TIfByJaU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam_wc = wc.generate(df[df['target'] == 1]['transformed_text'].str.cat(sep=\" \"))"
      ],
      "metadata": {
        "id": "m_oqO4ZbJaSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "plt.imshow(spam_wc)"
      ],
      "metadata": {
        "id": "JqPIkzDxJaPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ham_wc = wc.generate(df[df['target'] == 0]['transformed_text'].str.cat(sep=\" \"))"
      ],
      "metadata": {
        "id": "o_EIf6RZJaMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "plt.imshow(ham_wc)"
      ],
      "metadata": {
        "id": "EkDYo6GmJaJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam_corpus = []\n",
        "for msg in df[df['target'] == 1]['transformed_text'].tolist():\n",
        "  for words in msg.split():\n",
        "    spam_corpus.append(words)"
      ],
      "metadata": {
        "id": "wNC4svkGJaF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(spam_corpus)"
      ],
      "metadata": {
        "id": "tu29qPdjvM8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "temp_df = pd.DataFrame(Counter(spam_corpus).most_common(30))\n",
        "# Custom VIBGYOR color palette\n",
        "vibgyor_colors = ['#8A2BE2', '#4B0082', '#0000FF', '#008000', '#FFFF00', '#FFA500', '#FF0000']\n",
        "sns.barplot(x=temp_df[0], y=temp_df[1], hue=temp_df[0], palette=vibgyor_colors, legend=False)\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DvycZEn3vM47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ham_corpus = []\n",
        "for msg in df[df['target'] == 0]['transformed_text'].tolist():\n",
        "  for words in msg.split():\n",
        "    ham_corpus.append(words)"
      ],
      "metadata": {
        "id": "tjLAfnd6vM2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50e63431"
      },
      "source": [
        "len(ham_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83cb6497"
      },
      "source": [
        "from collections import Counter\n",
        "temp_df = pd.DataFrame(Counter(ham_corpus).most_common(30))\n",
        "# Custom VIBGYOR color palette\n",
        "vibgyor_colors = ['#8A2BE2', '#4B0082', '#0000FF', '#008000', '#FFFF00', '#FFA500', '#FF0000']\n",
        "sns.barplot(x=temp_df[0], y=temp_df[1], hue=temp_df[0], palette=vibgyor_colors, legend=False)\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "rprBSdHw0VC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "***MODEL BUILDING***"
      ],
      "metadata": {
        "id": "WiKbQ1sszw5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "cv = CountVectorizer()\n",
        "tfidf = TfidfVectorizer(max_features=3000)"
      ],
      "metadata": {
        "id": "S-XIPFnAvMww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = tfidf.fit_transform(df['transformed_text']).toarray()"
      ],
      "metadata": {
        "id": "igF_VtGHvMuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.preprocessing import MinMaxScaler\n",
        "#scaler = MinMaxScaler()\n",
        "#X = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "BERRsIGUvMrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# appending the num_character col to X\n",
        "#X = np.hstack((X,df['num_characters'].values.reshape(-1,1)))"
      ],
      "metadata": {
        "id": "2ydYQJ5e4ASh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "Lld63sND4H_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df['target'].values"
      ],
      "metadata": {
        "id": "FL6896AHvMos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "id": "g5XcSfcBvMl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "JTyITepOJaCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2, random_state=2)"
      ],
      "metadata": {
        "id": "jXoCq_vQ18gR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score"
      ],
      "metadata": {
        "id": "lv54EpLh18cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gnb = GaussianNB()\n",
        "mnb = MultinomialNB()\n",
        "bnb = BernoulliNB()"
      ],
      "metadata": {
        "id": "FTAqEGXm18ZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gnb.fit(X_train,Y_train)\n",
        "y_pred1 = gnb.predict(X_test)\n",
        "print(accuracy_score  (Y_test,y_pred1))\n",
        "print(confusion_matrix(Y_test,y_pred1))\n",
        "print(precision_score (Y_test,y_pred1))"
      ],
      "metadata": {
        "id": "4c_vOJ8u18V2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnb.fit(X_train,Y_train)\n",
        "y_pred2 = mnb.predict(X_test)\n",
        "print(accuracy_score  (Y_test,y_pred2))\n",
        "print(confusion_matrix(Y_test,y_pred2))\n",
        "print(precision_score (Y_test,y_pred2))"
      ],
      "metadata": {
        "id": "fXUQI6ly18Sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnb.fit(X_train,Y_train)\n",
        "y_pred3 = bnb.predict(X_test)\n",
        "print(accuracy_score  (Y_test,y_pred3))\n",
        "print(confusion_matrix(Y_test,y_pred3))\n",
        "print(precision_score (Y_test,y_pred3))"
      ],
      "metadata": {
        "id": "FGw6PDGI18PJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tfidf --> MNB"
      ],
      "metadata": {
        "id": "ayO-tFdS4ebx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "QYjrtyma4eZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc = SVC(kernel='sigmoid', gamma=1.0)\n",
        "knc = KNeighborsClassifier()\n",
        "mnb = MultinomialNB()\n",
        "dtc = DecisionTreeClassifier(max_depth=5)\n",
        "lrc = LogisticRegression(solver='liblinear', penalty='l1')\n",
        "rfc = RandomForestClassifier(n_estimators=50, random_state=2)\n",
        "abc = AdaBoostClassifier(n_estimators=50, random_state=2)\n",
        "bc = BaggingClassifier(n_estimators=50, random_state=2)\n",
        "etc = ExtraTreesClassifier(n_estimators=50, random_state=2)\n",
        "gbdt = GradientBoostingClassifier(n_estimators=50,random_state=2)\n",
        "xgb = XGBClassifier(n_estimators=50,random_state=2)"
      ],
      "metadata": {
        "id": "OGleykWh4eXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clfs = {\n",
        "    'SVC' : svc,\n",
        "    'KN' : knc,\n",
        "    'NB': mnb,\n",
        "    'DT': dtc,\n",
        "    'LR': lrc,\n",
        "    'RF': rfc,\n",
        "    'AdaBoost': abc,\n",
        "    'BgC': bc,\n",
        "    'ETC': etc,\n",
        "    'GBDT':gbdt,\n",
        "    'xgb':xgb\n",
        "}"
      ],
      "metadata": {
        "id": "Sq-zYP774eVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_classifier(clf,X_train,y_train,X_test,y_test):\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test,y_pred)\n",
        "    precision = precision_score(y_test,y_pred)\n",
        "\n",
        "    return accuracy,precision"
      ],
      "metadata": {
        "id": "jAgwCuLB4eTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_classifier(svc,X_train,Y_train,X_test,Y_test)"
      ],
      "metadata": {
        "id": "s8ylYyX94eRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for name,clf in clfs.items():\n",
        "\n",
        "    current_accuracy,current_precision = train_classifier(clf, X_train,Y_train,X_test,Y_test)\n",
        "\n",
        "    print(\"For \",name)\n",
        "    print(\"Accuracy - \",current_accuracy)\n",
        "    print(\"Precision - \",current_precision)\n",
        "\n",
        "    accuracy_scores.append(current_accuracy)\n",
        "    precision_scores.append(current_precision)"
      ],
      "metadata": {
        "id": "GtmLajjl4ePg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "performance_df = pd.DataFrame({'Algorithm':clfs.keys(),'Accuracy':accuracy_scores,'Precision':precision_scores}).sort_values('Precision',ascending=False)"
      ],
      "metadata": {
        "id": "Xpsyj0TA4eNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "performance_df"
      ],
      "metadata": {
        "id": "Hbqh0_rT4eLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "performance_df1 = pd.melt(performance_df, id_vars = \"Algorithm\")"
      ],
      "metadata": {
        "id": "LDoKDQQj4eJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "performance_df1"
      ],
      "metadata": {
        "id": "eF2DTCI24eHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.catplot(x = 'Algorithm', y='value',\n",
        "               hue = 'variable',data=performance_df1, kind='bar',height=5)\n",
        "plt.ylim(0.5,1.0)\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OCCWPvco4eFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model improve\n",
        "# 1. Change the max_features parameter of TfIdf"
      ],
      "metadata": {
        "id": "3c8VZXz65IsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df = pd.DataFrame({'Algorithm':clfs.keys(),'Accuracy_max_ft_3000':accuracy_scores,'Precision_max_ft_3000':precision_scores}).sort_values('Precision_max_ft_3000',ascending=False)"
      ],
      "metadata": {
        "id": "wHOvT3vu5Io5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df = pd.DataFrame({'Algorithm':clfs.keys(),'Accuracy_scaling':accuracy_scores,'Precision_scaling':precision_scores}).sort_values('Precision_scaling',ascending=False)"
      ],
      "metadata": {
        "id": "qmx7AtPZ5ImA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = performance_df.merge(temp_df,on='Algorithm')"
      ],
      "metadata": {
        "id": "RG4ZEcmI5Ii_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df_scaled = new_df.merge(temp_df,on='Algorithm')"
      ],
      "metadata": {
        "id": "1hbIt2Yb5IgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df = pd.DataFrame({'Algorithm':clfs.keys(),'Accuracy_num_chars':accuracy_scores,'Precision_num_chars':precision_scores}).sort_values('Precision_num_chars',ascending=False)"
      ],
      "metadata": {
        "id": "ejNsA4Tz5Idi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df_scaled.merge(temp_df,on='Algorithm')"
      ],
      "metadata": {
        "id": "8z1WkQlo5rCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Voting Classifier\n",
        "svc = SVC(kernel='sigmoid', gamma=1.0,probability=True)\n",
        "mnb = MultinomialNB()\n",
        "etc = ExtraTreesClassifier(n_estimators=50, random_state=2)\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier"
      ],
      "metadata": {
        "id": "B4djfuB95sa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voting = VotingClassifier(estimators=[('svm', svc), ('nb', mnb), ('et', etc)],voting='soft')"
      ],
      "metadata": {
        "id": "rMN4FjhU5sY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voting.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "_HpTv9sZ5sWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = voting.predict(X_test)\n",
        "print(\"Accuracy\",accuracy_score(Y_test,y_pred))\n",
        "print(\"Precision\",precision_score(Y_test,y_pred))"
      ],
      "metadata": {
        "id": "Y-gIzM9j5sU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying stacking\n",
        "estimators=[('svm', svc), ('nb', mnb), ('et', etc)]\n",
        "final_estimator=RandomForestClassifier()"
      ],
      "metadata": {
        "id": "xGpQTS0s5sSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingClassifier"
      ],
      "metadata": {
        "id": "ykv2hzQT5sQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = StackingClassifier(estimators=estimators, final_estimator=final_estimator)"
      ],
      "metadata": {
        "id": "BjGhlYlb5sOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(X_train,Y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy\",accuracy_score(Y_test,y_pred))\n",
        "print(\"Precision\",precision_score(Y_test,y_pred))"
      ],
      "metadata": {
        "id": "0sQMTPcs5sMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Re-initialize and fit MultinomialNB to ensure the saved model is fitted\n",
        "mnb_fitted = MultinomialNB()\n",
        "mnb_fitted.fit(X_train, Y_train)\n",
        "\n",
        "pickle.dump(tfidf,open('vectorizer.pkl','wb'))\n",
        "pickle.dump(mnb_fitted,open('model.pkl','wb'))"
      ],
      "metadata": {
        "id": "3v7sqwA05rAf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}